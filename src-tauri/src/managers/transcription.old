// use kalosm::sound::rodio::buffer::SamplesBuffer;
// use kalosm::sound::{ModelLoadingProgress, TextStream, Whisper, WhisperBuilder, WhisperSource};

// pub struct TranscriptionManager {
//     model: Whisper,
// }

// impl TranscriptionManager {
//     pub fn new() -> Result<Self, Box<dyn std::error::Error>> {
//         let model = tauri::async_runtime::block_on(async {
//             WhisperBuilder::default()
//                 .with_source(WhisperSource::Small)
//                 .build_with_loading_handler(|progress| match progress {
//                     ModelLoadingProgress::Downloading {
//                         source,
//                         start_time,
//                         progress,
//                     } => {
//                         let progress = (progress * 100.0) as u32;
//                         let elapsed = start_time.elapsed().as_secs_f32();
//                         println!("Downloading file {source} {progress}% ({elapsed}s)");
//                     }
//                     ModelLoadingProgress::Loading { progress } => {
//                         let progress = (progress * 100.0) as u32;
//                         println!("Loading model {progress}%");
//                     }
//                 })
//                 .await
//         })?;

//         Ok(Self { model })
//     }

//     pub fn transcribe(&self, audio: SamplesBuffer<f32>) -> Result<String, anyhow::Error> {
//         let mut result = String::new();

//         println!("lot line transcribing");
//         let mut transcribed = self.model.transcribe(audio)?;
//         println!("Sync transcribing finished");

//         use std::time::Instant;

//         let start = Instant::now();
//         tauri::async_runtime::block_on(async {
//             transcribed.to_std_out().await.unwrap();
//         });
//         let duration = start.elapsed();
//         println!("Time elapsed: {:?}", duration);

//         // let segments = tauri::async_runtime::block_on(async {
//         //     let mut segments = Vec::new();
//         //     let mut stream = transcribed;
//         //     while let Some(segment) = stream.next().await {
//         //         segments.push(segment);
//         //     }
//         //     segments
//         // });

//         // for segment in segments {
//         //     if segment.probability_of_no_speech() < 0.10 {
//         //         result.push_str(segment.text());
//         //     }
//         // }

//         Ok(result)
//     }
// }